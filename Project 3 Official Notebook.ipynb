{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Reddit's API to Predict Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Executive Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this notebook, I aim to answer the question: what characteristics of a post on Reddit contribute most to what subreddit it belongs to?\n",
    "#### Specifically, when comparing two subreddits, what words in title let you know which subreddit is from?\n",
    "\n",
    "#### The two subreddits I chose to compare were the NBA (National Basketball Association) and the 76ers ( a team in the NBA). I did this since it seemed like a good edge-case to test. Both subreddits have similar subject matter which might lead to a reduced accuracy score but it would be interesting to see how well the models perform. \n",
    "\n",
    "#### In order to even start answering this question, we must first gather the data we wish to use from each subreddit. In order to do this we use the requests and json library in python to extract data from the json reddits pages. In this part of the project I had to explore the json files in order to find where my desired information was located. Once I determined that, I made requests from reddit for posts and got around 800 posts for each subreddit. From there I explored the data more and decided it was best for me to use the title as the basis for my classification as there was not much selftext. \n",
    "\n",
    "#### From there I used a Count Vectorizer and TFIDF Vectorizer to transform the titles into easily digestable features for my models. For my targets , I made the 76ers a 1 and the NBA a 0. The models I decided to go with were the Logistic Regression, Random Forest Classifier, and the Multinomial Naive Bayes models. \n",
    "\n",
    "#### After doing Logistic Regression, I looked at words that came up the most frequently and it turned out to be mostly names of famous NBA players. For the NBA coefficients players that were famous industry-wide were listed and for the 76ers coefficients , star players of the team were mentioned a lot. \n",
    "\n",
    "#### Overall, all the model performed similarly, overfitting on training data and getting lower scores for test. Mulitnomial Naive Bayes performed the best, but it wasn't much better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Science Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"width:25%\" align=\"left\">\n",
    "  <tr>\n",
    "    <th style=\"text-align:left\">1. Define the problem.</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <th style=\"text-align:left\">2. Gather the data.</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <th style=\"text-align:left\">3. Explore the data.</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <th style=\"text-align:left\">4. Model the data.</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <th style=\"text-align:left\">5. Evaluate the model.</th>\n",
    "  </tr> \n",
    "  <tr>\n",
    "    <th style=\"text-align:left\">6. Answer the problem.</th>\n",
    "  </tr> \n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <u>1. Define the Problem :</u>\n",
    "### What characteristics of a post on Reddit contribute most to what subreddit it belongs to?\n",
    "#### Specifically, I'll be looking at which words in the title contribute most to the identifying which subreddit a post belongs to\n",
    "#### I did not use self -text since some of the posts didn't have self-text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "===================================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <u> 2. Gather the Data</u>\n",
    "#### Here I'll webscrape posts from two subreddits to later process and create models from.\n",
    "#### The two subreddits I'll be comparing in this iteration are the <u>NBA and 76ers</u> subreddits (76ers are a basketball team in the NBA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "===================================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.feature_extraction import stop_words\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Function for webscraping from Reddit**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(User_agent , num_of_posts ,url ,next_post = \"after\"):\n",
    "    \n",
    "    #User_agent - user agent that will make requests\n",
    "    #num_of_posts - number of times we request data \n",
    "    #url - url that we want to scrape from , should have .json at the end of it\n",
    "    #next_post - user can choose whether to scrape to the previous('before') or next('after') post\n",
    "    \n",
    "    #list of all posts\n",
    "    all_posts = []\n",
    "    #URL\n",
    "    URL = url\n",
    "    #update 'after' with this parameter\n",
    "    p = {}\n",
    "    \n",
    "    for i in range(num_of_posts):\n",
    "        #get request\n",
    "        res = requests.get(URL,params = p,headers = {\"User-agent\": User_agent})\n",
    "        #wait till you have the data\n",
    "        res.raise_for_status()\n",
    "        #get json file\n",
    "        data = res.json()\n",
    "        \n",
    "        #get posts for this request\n",
    "        list_of_posts = data['data'][\"children\"]\n",
    "        \n",
    "        #add to all_posts\n",
    "        all_posts = all_posts + list_of_posts\n",
    "        \n",
    "        #get the after to add \n",
    "        after = data['data'][next_post]\n",
    "        \n",
    "        #If none , return \n",
    "        if after == None:\n",
    "            print(\"No posts\")\n",
    "            break\n",
    "        \n",
    "        #otherwise update the p\n",
    "        else:\n",
    "            p.update({'after':after})\n",
    "            #URL = URL+\"?after=\" + after\n",
    "            print(\"The current after: \", after,\" \",i ,\": size: \",len(list_of_posts))\n",
    "        #time.sleep(sleep_time)\n",
    "        \n",
    "    #get the keys to name columns\n",
    "    keyz =[x for x in all_posts[0][\"data\"].keys()]\n",
    "    \n",
    "    #list of values for the dataframe\n",
    "    list_of_values = []\n",
    "    \n",
    "    for index in range(len(all_posts)):\n",
    "        \n",
    "        #get each request \n",
    "        valuez = [x for x in all_posts[index][\"data\"].values()]\n",
    "        \n",
    "        #append to list\n",
    "        list_of_values.append(valuez)\n",
    "        \n",
    "        #if for some reason some posts have different number of columns\n",
    "        #get the greatest number of columns and make those your columns names\n",
    "        #for the DataFrame\n",
    "        if len([x for x in all_posts[index][\"data\"].keys()])>len(keyz):\n",
    "            keyz = [x for x in all_posts[index][\"data\"].keys()]\n",
    "            \n",
    "    #Create DataFrame        \n",
    "    data_df = pd.DataFrame(columns = keyz, data = list_of_values)\n",
    "    return data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get data from the sixers and NBA subreddits to compare**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sixers = pd.DataFrame(get_data(\"Bobby\",40,\"https://www.reddit.com/r/sixers.json\"))\n",
    "#nba = pd.DataFrame(get_data(\"Bobby\",40,\"https://www.reddit.com/r/nba.json\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Export both DataFrames to a csv so I don't have to scrape again later**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export both to csv\n",
    "# sixers.to_csv('both.csv')\n",
    "\n",
    "# with open('both.csv', 'a',encoding='utf-8') as f:\n",
    "#     nba.to_csv(f)\n",
    "\n",
    "# #Export each dataframe individually just in case\n",
    "# nba.to_csv('nba.csv')\n",
    "# sixers.to_csv('sixers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "both = pd.read_csv(\"both.csv\").copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "nba = both[both[\"subreddit\"]=='nba'].copy()\n",
    "sixers = both[both[\"subreddit\"]=='sixers'].copy()\n",
    "nba.reset_index(inplace = True)\n",
    "sixers.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "sixers.drop(labels = [\"index\",\"Unnamed: 0\"], axis = 1,inplace = True)\n",
    "nba.drop(labels = [\"index\",\"Unnamed: 0\"], axis = 1,inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Explore the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>approved_at_utc</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>selftext</th>\n",
       "      <th>author_fullname</th>\n",
       "      <th>saved</th>\n",
       "      <th>mod_reason_title</th>\n",
       "      <th>gilded</th>\n",
       "      <th>clicked</th>\n",
       "      <th>title</th>\n",
       "      <th>link_flair_richtext</th>\n",
       "      <th>...</th>\n",
       "      <th>crosspost_parent</th>\n",
       "      <th>author_flair_text_color</th>\n",
       "      <th>permalink</th>\n",
       "      <th>parent_whitelist_status</th>\n",
       "      <th>stickied</th>\n",
       "      <th>url</th>\n",
       "      <th>subreddit_subscribers</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>media</th>\n",
       "      <th>is_video</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>sixers</td>\n",
       "      <td>It's that time. The off-season clock appears t...</td>\n",
       "      <td>t2_fcq7v</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>[Off-Season Thread] Waitin' for training camp...</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>https://www.reddit.com/r/sixers/comments/91uj4...</td>\n",
       "      <td>42353</td>\n",
       "      <td>1532543892.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>sixers</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t2_txalw</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Ben with LeBron.</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>all_ads</td>\n",
       "      <td>False</td>\n",
       "      <td>https://www.instagram.com/p/BnWVp7wn0d_/?taken...</td>\n",
       "      <td>42353</td>\n",
       "      <td>1536160451.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>sixers</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t2_kaek1sc</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>#HereTheyCome Kelle hitting the gym! F2G</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>all_ads</td>\n",
       "      <td>False</td>\n",
       "      <td>https://i.redd.it/mp7g7g7tigk11.jpg</td>\n",
       "      <td>42353</td>\n",
       "      <td>1536169408.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>sixers</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t2_12vc6g</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>One of the trainers that is studying under Han...</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>all_ads</td>\n",
       "      <td>False</td>\n",
       "      <td>https://i.redd.it/z205by4ymhk11.jpg</td>\n",
       "      <td>42353</td>\n",
       "      <td>1536182917.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>sixers</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t2_swp0e</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>14$ well spent on my first jersey</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>all_ads</td>\n",
       "      <td>False</td>\n",
       "      <td>https://i.redd.it/h8nk24d0ygk11.jpg</td>\n",
       "      <td>42353</td>\n",
       "      <td>1536174546.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 96 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  approved_at_utc subreddit  \\\n",
       "0             NaN    sixers   \n",
       "1             NaN    sixers   \n",
       "2             NaN    sixers   \n",
       "3             NaN    sixers   \n",
       "4             NaN    sixers   \n",
       "\n",
       "                                            selftext author_fullname  saved  \\\n",
       "0  It's that time. The off-season clock appears t...        t2_fcq7v  False   \n",
       "1                                                NaN        t2_txalw  False   \n",
       "2                                                NaN      t2_kaek1sc  False   \n",
       "3                                                NaN       t2_12vc6g  False   \n",
       "4                                                NaN        t2_swp0e  False   \n",
       "\n",
       "  mod_reason_title gilded clicked  \\\n",
       "0              NaN      0   False   \n",
       "1              NaN      0   False   \n",
       "2              NaN      0   False   \n",
       "3              NaN      0   False   \n",
       "4              NaN      0   False   \n",
       "\n",
       "                                               title link_flair_richtext  \\\n",
       "0   [Off-Season Thread] Waitin' for training camp...                  []   \n",
       "1                                   Ben with LeBron.                  []   \n",
       "2           #HereTheyCome Kelle hitting the gym! F2G                  []   \n",
       "3  One of the trainers that is studying under Han...                  []   \n",
       "4                  14$ well spent on my first jersey                  []   \n",
       "\n",
       "    ...                                      crosspost_parent  \\\n",
       "0   ...     https://www.reddit.com/r/sixers/comments/91uj4...   \n",
       "1   ...                                               all_ads   \n",
       "2   ...                                               all_ads   \n",
       "3   ...                                               all_ads   \n",
       "4   ...                                               all_ads   \n",
       "\n",
       "  author_flair_text_color                                          permalink  \\\n",
       "0                   42353                                       1532543892.0   \n",
       "1                   False  https://www.instagram.com/p/BnWVp7wn0d_/?taken...   \n",
       "2                   False                https://i.redd.it/mp7g7g7tigk11.jpg   \n",
       "3                   False                https://i.redd.it/z205by4ymhk11.jpg   \n",
       "4                   False                https://i.redd.it/h8nk24d0ygk11.jpg   \n",
       "\n",
       "  parent_whitelist_status      stickied  url subreddit_subscribers  \\\n",
       "0                     NaN         False  NaN                   NaN   \n",
       "1                   42353  1536160451.0  NaN                 False   \n",
       "2                   42353  1536169408.0  NaN                 False   \n",
       "3                   42353  1536182917.0  NaN                 False   \n",
       "4                   42353  1536174546.0  NaN                 False   \n",
       "\n",
       "  created_utc media is_video  \n",
       "0         NaN   NaN      NaN  \n",
       "1         NaN   NaN      NaN  \n",
       "2         NaN   NaN      NaN  \n",
       "3         NaN   NaN      NaN  \n",
       "4         NaN   NaN      NaN  \n",
       "\n",
       "[5 rows x 96 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sixers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>approved_at_utc</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>selftext</th>\n",
       "      <th>author_fullname</th>\n",
       "      <th>saved</th>\n",
       "      <th>mod_reason_title</th>\n",
       "      <th>gilded</th>\n",
       "      <th>clicked</th>\n",
       "      <th>title</th>\n",
       "      <th>link_flair_richtext</th>\n",
       "      <th>...</th>\n",
       "      <th>crosspost_parent</th>\n",
       "      <th>author_flair_text_color</th>\n",
       "      <th>permalink</th>\n",
       "      <th>parent_whitelist_status</th>\n",
       "      <th>stickied</th>\n",
       "      <th>url</th>\n",
       "      <th>subreddit_subscribers</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>media</th>\n",
       "      <th>is_video</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>nba</td>\n",
       "      <td>#[/r/NBA Rules](https://www.reddit.com/r/nba/w...</td>\n",
       "      <td>t2_6l4z3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Daily Locker Room and Free Talk + Game Threads...</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>1536153318.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>nba</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t2_hn4t5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>r/nba Best of August</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>1535901297.0</td>\n",
       "      <td>{'oembed': {'provider_url': 'http://imgur.com'...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>nba</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t2_kk5v7</td>\n",
       "      <td>Misc. Media</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>New Nike commercial featuring Lebron, Kaeperni...</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>1536175454.0</td>\n",
       "      <td>{'oembed': {'provider_url': 'https://streamabl...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>nba</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t2_ao907</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>LeBron James says he 'stands with Nike' in ref...</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>1536151457.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>nba</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t2_nqx3n</td>\n",
       "      <td>Highlights</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Chris Paul taps D-Rose on the left side twice ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>1536177024.0</td>\n",
       "      <td>{'type': 'streamable.com', 'oembed': {'provide...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 96 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  approved_at_utc subreddit  \\\n",
       "0             NaN       nba   \n",
       "1             NaN       nba   \n",
       "2             NaN       nba   \n",
       "3             NaN       nba   \n",
       "4             NaN       nba   \n",
       "\n",
       "                                            selftext author_fullname  \\\n",
       "0  #[/r/NBA Rules](https://www.reddit.com/r/nba/w...        t2_6l4z3   \n",
       "1                                                NaN        t2_hn4t5   \n",
       "2                                                NaN        t2_kk5v7   \n",
       "3                                                NaN        t2_ao907   \n",
       "4                                                NaN        t2_nqx3n   \n",
       "\n",
       "         saved mod_reason_title gilded clicked  \\\n",
       "0          NaN              NaN      0   False   \n",
       "1          NaN              NaN      0   False   \n",
       "2  Misc. Media              NaN      0   False   \n",
       "3          NaN              NaN      0   False   \n",
       "4   Highlights              NaN      0   False   \n",
       "\n",
       "                                               title link_flair_richtext  \\\n",
       "0  Daily Locker Room and Free Talk + Game Threads...                  []   \n",
       "1                               r/nba Best of August                  []   \n",
       "2  New Nike commercial featuring Lebron, Kaeperni...                  []   \n",
       "3  LeBron James says he 'stands with Nike' in ref...                  []   \n",
       "4  Chris Paul taps D-Rose on the left side twice ...                  []   \n",
       "\n",
       "    ...    crosspost_parent  \\\n",
       "0   ...        1536153318.0   \n",
       "1   ...        1535901297.0   \n",
       "2   ...        1536175454.0   \n",
       "3   ...        1536151457.0   \n",
       "4   ...        1536177024.0   \n",
       "\n",
       "                             author_flair_text_color permalink  \\\n",
       "0                                                NaN     False   \n",
       "1  {'oembed': {'provider_url': 'http://imgur.com'...     False   \n",
       "2  {'oembed': {'provider_url': 'https://streamabl...     False   \n",
       "3                                                NaN     False   \n",
       "4  {'type': 'streamable.com', 'oembed': {'provide...     False   \n",
       "\n",
       "  parent_whitelist_status stickied  url subreddit_subscribers created_utc  \\\n",
       "0                     NaN      NaN  NaN                   NaN         NaN   \n",
       "1                     NaN      NaN  NaN                   NaN         NaN   \n",
       "2                     NaN      NaN  NaN                   NaN         NaN   \n",
       "3                     NaN      NaN  NaN                   NaN         NaN   \n",
       "4                     NaN      NaN  NaN                   NaN         NaN   \n",
       "\n",
       "  media is_video  \n",
       "0   NaN      NaN  \n",
       "1   NaN      NaN  \n",
       "2   NaN      NaN  \n",
       "3   NaN      NaN  \n",
       "4   NaN      NaN  \n",
       "\n",
       "[5 rows x 96 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nba.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sixers Null values - selftext, title :  680 , 0\n",
      "NBA Null values - selftext, title :  314 , 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Sixers Null values - selftext, title : \",\n",
    "sixers[\"selftext\"].isna().sum() ,\",\", sixers[\"title\"].isna().sum())\n",
    "print(\"NBA Null values - selftext, title : \",\n",
    "nba[\"selftext\"].isna().sum() ,\",\", nba[\"title\"].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sixers rows:  816\n",
      "nba rows:  778\n"
     ]
    }
   ],
   "source": [
    "print(\"sixers rows: \",sixers.shape[0])\n",
    "print(\"nba rows: \", nba.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**>>>> It seems that a large portion of the self-text of both subreddits are null values so I'm deciding to not look at them**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Model the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <u> NLP:</u> \n",
    "# Logistic Regression , Random Forest Classifier, Multinomial  Naive Bayes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "============================================================================================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load features and target and do a train-test split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = both.title\n",
    "y = both.subreddit.map(lambda x : x == both[\"subreddit\"][0])*1\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for printing out coefficents for each feature\n",
    "\n",
    "def coef_name_values(model):\n",
    "    #Get the feature names (words) and coefficents for each one\n",
    "    vect_names = model.steps[0][1].get_feature_names()\n",
    "    logis_coef = model.steps[1][1].coef_\n",
    "\n",
    "    #Put them into a DataFrame\n",
    "    coefs_of_names = pd.DataFrame(data = logis_coef, columns=vect_names)\n",
    "\n",
    "    #Sort these coefs to see which ones pop-up the most\n",
    "    print(\"Sorted Coefficent Values\")\n",
    "    return coefs_of_names.sort_values(by =0,axis = 1)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use Pipelines for Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_stopwords = list(stop_words.ENGLISH_STOP_WORDS)\n",
    "custom_stopwords.extend(['nba','sixers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9949832775919732, 0.7944862155388471)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Count Vectorizer\n",
    "steps1 = [\n",
    "    ('Count_Vectorize', CountVectorizer(stop_words = custom_stopwords)),\n",
    "    ('Log', LogisticRegression())\n",
    "]\n",
    "\n",
    "model_log = Pipeline(steps1)\n",
    "model_log.fit(X_train,y_train)\n",
    "model_log.score(X_train,y_train),model_log.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorted Coefficent Values\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>players</th>\n",
       "      <td>-1.861337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lebron</th>\n",
       "      <td>-1.210550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deng</th>\n",
       "      <td>-1.204360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kobe</th>\n",
       "      <td>-1.169204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>career</th>\n",
       "      <td>-1.147953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>curry</th>\n",
       "      <td>-1.077196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>playoffs</th>\n",
       "      <td>-1.072901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>klay</th>\n",
       "      <td>-1.035761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jordan</th>\n",
       "      <td>-1.029370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>durant</th>\n",
       "      <td>-1.021310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>paul</th>\n",
       "      <td>-0.980156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wnba</th>\n",
       "      <td>-0.974301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>magic</th>\n",
       "      <td>-0.966779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>player</th>\n",
       "      <td>-0.960965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>westbrook</th>\n",
       "      <td>-0.952665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nash</th>\n",
       "      <td>-0.948610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>playoff</th>\n",
       "      <td>-0.906816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predictions</th>\n",
       "      <td>-0.905599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dunk</th>\n",
       "      <td>-0.879692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>james</th>\n",
       "      <td>-0.868695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kevin</th>\n",
       "      <td>-0.868495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>won</th>\n",
       "      <td>-0.858577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prime</th>\n",
       "      <td>-0.852089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>points</th>\n",
       "      <td>-0.840112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>better</th>\n",
       "      <td>-0.830639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>team</th>\n",
       "      <td>-0.810988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>overrated</th>\n",
       "      <td>-0.806413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>warriors</th>\n",
       "      <td>-0.791703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>change</th>\n",
       "      <td>-0.778952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knicks</th>\n",
       "      <td>-0.778611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>today</th>\n",
       "      <td>0.726143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>harris</th>\n",
       "      <td>0.733235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kawhi</th>\n",
       "      <td>0.736172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tlc</th>\n",
       "      <td>0.766510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hanlen</th>\n",
       "      <td>0.767890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>korver</th>\n",
       "      <td>0.771027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pick</th>\n",
       "      <td>0.776160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brett</th>\n",
       "      <td>0.783324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hinkie</th>\n",
       "      <td>0.805083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jo</th>\n",
       "      <td>0.818825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>korkmaz</th>\n",
       "      <td>0.881238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bolden</th>\n",
       "      <td>0.912177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2k</th>\n",
       "      <td>0.941787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tj</th>\n",
       "      <td>0.943862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mood</th>\n",
       "      <td>1.074665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76ers</th>\n",
       "      <td>1.088992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>markelle</th>\n",
       "      <td>1.190139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>philadelphia</th>\n",
       "      <td>1.267989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>furkan</th>\n",
       "      <td>1.291796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gm</th>\n",
       "      <td>1.342362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simmons</th>\n",
       "      <td>1.394325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fultz</th>\n",
       "      <td>1.398201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thread</th>\n",
       "      <td>1.402611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>joel</th>\n",
       "      <td>1.444910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>philly</th>\n",
       "      <td>1.487023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>muscala</th>\n",
       "      <td>1.612716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zhaire</th>\n",
       "      <td>1.660914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>process</th>\n",
       "      <td>1.774553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ben</th>\n",
       "      <td>1.953295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embiid</th>\n",
       "      <td>2.195213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3293 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0\n",
       "players      -1.861337\n",
       "lebron       -1.210550\n",
       "deng         -1.204360\n",
       "kobe         -1.169204\n",
       "career       -1.147953\n",
       "curry        -1.077196\n",
       "playoffs     -1.072901\n",
       "klay         -1.035761\n",
       "jordan       -1.029370\n",
       "durant       -1.021310\n",
       "paul         -0.980156\n",
       "wnba         -0.974301\n",
       "magic        -0.966779\n",
       "player       -0.960965\n",
       "westbrook    -0.952665\n",
       "nash         -0.948610\n",
       "playoff      -0.906816\n",
       "predictions  -0.905599\n",
       "dunk         -0.879692\n",
       "james        -0.868695\n",
       "kevin        -0.868495\n",
       "won          -0.858577\n",
       "prime        -0.852089\n",
       "points       -0.840112\n",
       "better       -0.830639\n",
       "team         -0.810988\n",
       "overrated    -0.806413\n",
       "warriors     -0.791703\n",
       "change       -0.778952\n",
       "knicks       -0.778611\n",
       "...                ...\n",
       "today         0.726143\n",
       "harris        0.733235\n",
       "kawhi         0.736172\n",
       "tlc           0.766510\n",
       "hanlen        0.767890\n",
       "korver        0.771027\n",
       "pick          0.776160\n",
       "brett         0.783324\n",
       "hinkie        0.805083\n",
       "jo            0.818825\n",
       "korkmaz       0.881238\n",
       "bolden        0.912177\n",
       "2k            0.941787\n",
       "tj            0.943862\n",
       "mood          1.074665\n",
       "76ers         1.088992\n",
       "markelle      1.190139\n",
       "philadelphia  1.267989\n",
       "furkan        1.291796\n",
       "gm            1.342362\n",
       "simmons       1.394325\n",
       "fultz         1.398201\n",
       "thread        1.402611\n",
       "joel          1.444910\n",
       "philly        1.487023\n",
       "muscala       1.612716\n",
       "zhaire        1.660914\n",
       "process       1.774553\n",
       "ben           1.953295\n",
       "embiid        2.195213\n",
       "\n",
       "[3293 rows x 1 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_name_values(model_log).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9690635451505016, 0.7969924812030075)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TFIDF Vectroizer\n",
    "steps1 = [\n",
    "    ('TF_Vectorize', TfidfVectorizer(stop_words = custom_stopwords,)),\n",
    "    ('Log', LogisticRegression())\n",
    "]\n",
    "\n",
    "model_log1 = Pipeline(steps1)\n",
    "model_log1.fit(X_train,y_train)\n",
    "model_log1.score(X_train,y_train),model_log1.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorted Coefficent Values\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>players</th>\n",
       "      <td>-2.357845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lebron</th>\n",
       "      <td>-1.755325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kobe</th>\n",
       "      <td>-1.377357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>player</th>\n",
       "      <td>-1.252106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>team</th>\n",
       "      <td>-1.211135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>curry</th>\n",
       "      <td>-1.147751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deng</th>\n",
       "      <td>-1.115470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>durant</th>\n",
       "      <td>-1.114854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>career</th>\n",
       "      <td>-1.030400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kevin</th>\n",
       "      <td>-1.024363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jordan</th>\n",
       "      <td>-1.018629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <td>-1.017258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>points</th>\n",
       "      <td>-1.007656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scoring</th>\n",
       "      <td>-1.005536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>best</th>\n",
       "      <td>-0.954994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>klay</th>\n",
       "      <td>-0.951661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>playoffs</th>\n",
       "      <td>-0.950297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prime</th>\n",
       "      <td>-0.937715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>james</th>\n",
       "      <td>-0.935268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>playoff</th>\n",
       "      <td>-0.915351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>paul</th>\n",
       "      <td>-0.903048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>westbrook</th>\n",
       "      <td>-0.879756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nash</th>\n",
       "      <td>-0.869303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wnba</th>\n",
       "      <td>-0.831473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>better</th>\n",
       "      <td>-0.822690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>luol</th>\n",
       "      <td>-0.801194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>warriors</th>\n",
       "      <td>-0.801071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>harden</th>\n",
       "      <td>-0.796715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oc</th>\n",
       "      <td>-0.772524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>magic</th>\n",
       "      <td>-0.766536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>guys</th>\n",
       "      <td>0.753589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zumoff</th>\n",
       "      <td>0.764114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>today</th>\n",
       "      <td>0.776956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>korver</th>\n",
       "      <td>0.781705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brett</th>\n",
       "      <td>0.788765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jo</th>\n",
       "      <td>0.829750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rookie</th>\n",
       "      <td>0.837508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>podcast</th>\n",
       "      <td>0.880312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>korkmaz</th>\n",
       "      <td>0.883704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hanlen</th>\n",
       "      <td>0.887589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2k</th>\n",
       "      <td>0.913613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bolden</th>\n",
       "      <td>0.924432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tj</th>\n",
       "      <td>0.946494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>summer</th>\n",
       "      <td>1.168891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mood</th>\n",
       "      <td>1.187448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>muscala</th>\n",
       "      <td>1.360970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thread</th>\n",
       "      <td>1.362580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>philadelphia</th>\n",
       "      <td>1.406504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gm</th>\n",
       "      <td>1.414513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>philly</th>\n",
       "      <td>1.479909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76ers</th>\n",
       "      <td>1.501086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>furkan</th>\n",
       "      <td>1.502754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zhaire</th>\n",
       "      <td>1.668047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>joel</th>\n",
       "      <td>1.787845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>process</th>\n",
       "      <td>1.841852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>markelle</th>\n",
       "      <td>1.905169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fultz</th>\n",
       "      <td>2.073244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simmons</th>\n",
       "      <td>2.139403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embiid</th>\n",
       "      <td>2.708799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ben</th>\n",
       "      <td>2.995851</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3293 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0\n",
       "players      -2.357845\n",
       "lebron       -1.755325\n",
       "kobe         -1.377357\n",
       "player       -1.252106\n",
       "team         -1.211135\n",
       "curry        -1.147751\n",
       "deng         -1.115470\n",
       "durant       -1.114854\n",
       "career       -1.030400\n",
       "kevin        -1.024363\n",
       "jordan       -1.018629\n",
       "class        -1.017258\n",
       "points       -1.007656\n",
       "scoring      -1.005536\n",
       "best         -0.954994\n",
       "klay         -0.951661\n",
       "playoffs     -0.950297\n",
       "prime        -0.937715\n",
       "james        -0.935268\n",
       "playoff      -0.915351\n",
       "paul         -0.903048\n",
       "westbrook    -0.879756\n",
       "nash         -0.869303\n",
       "wnba         -0.831473\n",
       "better       -0.822690\n",
       "luol         -0.801194\n",
       "warriors     -0.801071\n",
       "harden       -0.796715\n",
       "oc           -0.772524\n",
       "magic        -0.766536\n",
       "...                ...\n",
       "guys          0.753589\n",
       "zumoff        0.764114\n",
       "today         0.776956\n",
       "korver        0.781705\n",
       "brett         0.788765\n",
       "jo            0.829750\n",
       "rookie        0.837508\n",
       "podcast       0.880312\n",
       "korkmaz       0.883704\n",
       "hanlen        0.887589\n",
       "2k            0.913613\n",
       "bolden        0.924432\n",
       "tj            0.946494\n",
       "summer        1.168891\n",
       "mood          1.187448\n",
       "muscala       1.360970\n",
       "thread        1.362580\n",
       "philadelphia  1.406504\n",
       "gm            1.414513\n",
       "philly        1.479909\n",
       "76ers         1.501086\n",
       "furkan        1.502754\n",
       "zhaire        1.668047\n",
       "joel          1.787845\n",
       "process       1.841852\n",
       "markelle      1.905169\n",
       "fultz         2.073244\n",
       "simmons       2.139403\n",
       "embiid        2.708799\n",
       "ben           2.995851\n",
       "\n",
       "[3293 rows x 1 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_name_values(model_log1).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use Pipelines for a Random Forest Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9891304347826086, 0.7619047619047619)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steps2 = [\n",
    "    ('Count_Vectorize', CountVectorizer(stop_words = custom_stopwords)),\n",
    "    ('RFC', RandomForestClassifier())\n",
    "]\n",
    "\n",
    "model_rfc = Pipeline(steps2)\n",
    "model_rfc.fit(X_train,y_train)\n",
    "model_rfc.score(X_train,y_train),model_rfc.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9899665551839465, 0.8170426065162907)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steps2 = [\n",
    "    ('TF_Vectorize', TfidfVectorizer(stop_words = stop_words.ENGLISH_STOP_WORDS)),\n",
    "    ('RFC', RandomForestClassifier())\n",
    "]\n",
    "\n",
    "model_rfc1 = Pipeline(steps2)\n",
    "model_rfc1.fit(X_train,y_train)\n",
    "model_rfc1.score(X_train,y_train), model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use Pipelines for Multinomial Naive Bayes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9665551839464883, 0.8170426065162907)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steps3 = [\n",
    "   ('Count_Vectorize', CountVectorizer(stop_words = custom_stopwords)),\n",
    "    ('MultiNomialNB', MultinomialNB())\n",
    "]\n",
    "\n",
    "model_nb = Pipeline(steps3)\n",
    "model_nb.fit(X_train,y_train)\n",
    "model_nb.score(X_train,y_train),model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9749163879598662, 0.8170426065162907)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steps3 = [\n",
    "    ('TF_Vectorize', TfidfVectorizer(stop_words = custom_stopwords)),\n",
    "    ('MultiNomialNB', MultinomialNB())\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "model_nb1 = Pipeline(steps3)\n",
    "model_nb1.fit(X_train,y_train)\n",
    "model_nb1.score(X_train,y_train), model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Evaluate the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"NBA\",\"76ers\"]\n",
    "def print_cm(confusion_mat):\n",
    "    confusion_mat.columns = [\"Predicted NBA\",\"Predicted 76ers\"] \n",
    "    confusion_mat.index = [\"True NBA\" ,\"True 76ers\"]\n",
    "    return confusion_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_log = model_log.predict(X_test)\n",
    "y_pred_log1 = model_log1.predict(X_test)\n",
    "y_pred_rfc = model_rfc.predict(X_test)\n",
    "y_pred_rfc1 = model_rfc1.predict(X_test)\n",
    "y_pred_nb = model_nb.predict(X_test)\n",
    "y_pred_nb1 = model_nb1.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.76      0.78       189\n",
      "          1       0.79      0.83      0.81       210\n",
      "\n",
      "avg / total       0.79      0.79      0.79       399\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted NBA</th>\n",
       "      <th>Predicted 76ers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>True NBA</th>\n",
       "      <td>143</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True 76ers</th>\n",
       "      <td>36</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Predicted NBA  Predicted 76ers\n",
       "True NBA              143               46\n",
       "True 76ers             36              174"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Logiststic Regression with CountVec\n",
    "print(classification_report(y_test, y_pred_log))\n",
    "cm_log = pd.DataFrame(confusion_matrix(y_test, y_pred_log))\n",
    "print_cm(cm_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.80      0.79       189\n",
      "          1       0.81      0.80      0.80       210\n",
      "\n",
      "avg / total       0.80      0.80      0.80       399\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted NBA</th>\n",
       "      <th>Predicted 76ers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>True NBA</th>\n",
       "      <td>151</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True 76ers</th>\n",
       "      <td>43</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Predicted NBA  Predicted 76ers\n",
       "True NBA              151               38\n",
       "True 76ers             43              167"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Logiststic Regression with TFIDFVec\n",
    "print(classification_report(y_test, y_pred_log1))\n",
    "cm_log1 = pd.DataFrame(confusion_matrix(y_test, y_pred_log1))\n",
    "print_cm(cm_log1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted NBA</th>\n",
       "      <th>Predicted 76ers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>True NBA</th>\n",
       "      <td>120</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True 76ers</th>\n",
       "      <td>26</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Predicted NBA  Predicted 76ers\n",
       "True NBA              120               69\n",
       "True 76ers             26              184"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Random Forest with CountVec\n",
    "print(classification_report(y_test, y_pred_rfc))\n",
    "cm_rfc = pd.DataFrame(confusion_matrix(y_test, y_pred_rfc))\n",
    "print_cm(cm_rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.70      0.76       189\n",
      "          1       0.77      0.87      0.82       210\n",
      "\n",
      "avg / total       0.80      0.79      0.79       399\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted NBA</th>\n",
       "      <th>Predicted 76ers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>True NBA</th>\n",
       "      <td>133</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True 76ers</th>\n",
       "      <td>27</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Predicted NBA  Predicted 76ers\n",
       "True NBA              133               56\n",
       "True 76ers             27              183"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RandomForest with TFIDF\n",
    "print(classification_report(y_test, y_pred_rfc1))\n",
    "cm_rfc1 = pd.DataFrame(confusion_matrix(y_test, y_pred_rfc1))\n",
    "print_cm(cm_rfc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.78      0.80       189\n",
      "          1       0.81      0.85      0.83       210\n",
      "\n",
      "avg / total       0.82      0.82      0.82       399\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted NBA</th>\n",
       "      <th>Predicted 76ers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>True NBA</th>\n",
       "      <td>148</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True 76ers</th>\n",
       "      <td>32</td>\n",
       "      <td>178</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Predicted NBA  Predicted 76ers\n",
       "True NBA              148               41\n",
       "True 76ers             32              178"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Mulitnomial NB with CountVec\n",
    "print(classification_report(y_test, y_pred_nb))\n",
    "cm_nb = pd.DataFrame(confusion_matrix(y_test, y_pred_nb))\n",
    "print_cm(cm_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.77      0.80       189\n",
      "          1       0.81      0.86      0.83       210\n",
      "\n",
      "avg / total       0.82      0.82      0.82       399\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted NBA</th>\n",
       "      <th>Predicted 76ers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>True NBA</th>\n",
       "      <td>146</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True 76ers</th>\n",
       "      <td>30</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Predicted NBA  Predicted 76ers\n",
       "True NBA              146               43\n",
       "True 76ers             30              180"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Mulitnomial NB with TFIDF\n",
    "print(classification_report(y_test, y_pred_nb1))\n",
    "cm_nb1 = pd.DataFrame(confusion_matrix(y_test, y_pred_nb1))\n",
    "print_cm(cm_nb1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Answer the Problem\n",
    "**What characteristics of a post on Reddit contribute most to what subreddit it belongs to?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I specifically looked at what words in the title contributed to its classification. It turns out that names of players that are big in those fandoms were the ones that ended up determining the classification. Words like Curry, Lebron, and Kobe were words that made the classifier think a post belonged to the NBA subreddit. Words like Embiid, Joel, and Ben identified a post as being a part of 76ers subreddit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
